import logging
from openai import AsyncOpenAI
from config import CHATGPT_TOKEN

logger = logging.getLogger(__name__)
client = AsyncOpenAI(api_key=CHATGPT_TOKEN)


async def get_random_fact() -> str:
    try:
        response = await client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {
                    "role": "system",
                    "content": (
                        "Ð¢Ñ‹ Ð¿Ð¾Ð¼Ð¾Ñ‰Ð½Ð¸Ðº, ÐºÐ¾Ñ‚Ð¾Ñ€Ñ‹Ð¹ Ñ€Ð°ÑÑÐºÐ°Ð·Ñ‹Ð²Ð°ÐµÑ‚ "
                        "Ð¸Ð½Ñ‚ÐµÑ€ÐµÑÐ½Ñ‹Ðµ Ð¸ Ð¿Ð¾Ð·Ð½Ð°Ð²Ð°Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ðµ Ñ„Ð°ÐºÑ‚Ñ‹. "
                        "ÐžÑ‚Ð²ÐµÑ‡Ð°Ð¹ Ð½Ð° Ñ€ÑƒÑÑÐºÐ¾Ð¼ ÑÐ·Ñ‹ÐºÐµ."
                    )
                },
                {
                    "role": "user",
                    "content": (
                        "Ð Ð°ÑÑÐºÐ°Ð¶Ð¸ Ð¸Ð½Ñ‚ÐµÑ€ÐµÑÐ½Ñ‹Ð¹ ÑÐ»ÑƒÑ‡Ð°Ð¹Ð½Ñ‹Ð¹ Ñ„Ð°ÐºÑ‚ Ð¸Ð· "
                        "Ð»ÑŽÐ±Ð¾Ð¹ Ð¾Ð±Ð»Ð°ÑÑ‚Ð¸ Ð·Ð½Ð°Ð½Ð¸Ð¹. Ð¤Ð°ÐºÑ‚ Ð´Ð¾Ð»Ð¶ÐµÐ½ Ð±Ñ‹Ñ‚ÑŒ "
                        "Ð¿Ð¾Ð·Ð½Ð°Ð²Ð°Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ð¼, ÑƒÐ´Ð¸Ð²Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ð¼ Ð¸ Ð½Ðµ ÑÐ»Ð¸ÑˆÐºÐ¾Ð¼ "
                        "Ð´Ð»Ð¸Ð½Ð½Ñ‹Ð¼ (Ð¼Ð°ÐºÑÐ¸Ð¼ÑƒÐ¼ 3â€“4 Ð¿Ñ€ÐµÐ´Ð»Ð¾Ð¶ÐµÐ½Ð¸Ñ)."
                    )
                }
            ],
            max_tokens=200,
            temperature=0.8
        )
        fact = response.choices[0].message.content.strip()
        logger.info("Ð¤Ð°ÐºÑ‚ ÑƒÑÐ¿ÐµÑˆÐ½Ð¾ Ð¿Ð¾Ð»ÑƒÑ‡ÐµÐ½ Ð¾Ñ‚ OpenAI")
        return fact

    except Exception as e:
        logger.error(f"ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ Ð¿Ð¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ð¸ Ñ„Ð°ÐºÑ‚Ð° Ð¾Ñ‚ OpenAI: {e}")
        return "ðŸ¤” Ðš ÑÐ¾Ð¶Ð°Ð»ÐµÐ½Ð¸ÑŽ, Ð½Ðµ ÑƒÐ´Ð°Ð»Ð¾ÑÑŒ Ð¿Ð¾Ð»ÑƒÑ‡Ð¸Ñ‚ÑŒ Ñ„Ð°ÐºÑ‚ Ð² Ð´Ð°Ð½Ð½Ñ‹Ð¹ Ð¼Ð¾Ð¼ÐµÐ½Ñ‚."


async def ask_chatgpt(messages) -> str:
    try:
        response = await client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=messages,
            max_tokens=400,
            temperature=0.7
        )
        reply = response.choices[0].message.content.strip()
        logger.info("ÐžÑ‚Ð²ÐµÑ‚ ÑƒÑÐ¿ÐµÑˆÐ½Ð¾ Ð¿Ð¾Ð»ÑƒÑ‡ÐµÐ½ Ð¾Ñ‚ OpenAI")
        return reply

    except Exception as e:
        logger.error(f"ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ð¸ Ñ ChatGPT: {e}")
        return "ðŸ˜” Ðš ÑÐ¾Ð¶Ð°Ð»ÐµÐ½Ð¸ÑŽ, Ð½Ðµ ÑƒÐ´Ð°Ð»Ð¾ÑÑŒ Ð¿Ð¾Ð»ÑƒÑ‡Ð¸Ñ‚ÑŒ Ð¾Ñ‚Ð²ÐµÑ‚ Ð¾Ñ‚ ChatGPT."

async def get_quiz_question(theme: str) -> tuple[str, str]:
    system = ("Ð¢Ñ‹ Ð¿Ð¾Ð¼Ð¾Ñ‰Ð½Ð¸Ðº-Ð²Ð¸ÐºÑ‚Ð¾Ñ€Ð¸Ð½Ð°. Ð¡Ñ„Ð¾Ñ€Ð¼ÑƒÐ»Ð¸Ñ€ÑƒÐ¹ ÐžÐ”Ð˜Ð Ð²Ð¾Ð¿Ñ€Ð¾Ñ Ð¿Ð¾ Ñ‚ÐµÐ¼Ðµ Â«"
              f"{theme}Â» Ð¸ Ð´Ð°Ð¹ Ð¿Ñ€Ð°Ð²Ð¸Ð»ÑŒÐ½Ñ‹Ð¹ Ð¾Ñ‚Ð²ÐµÑ‚ Ð² JSON:"
              r' {"question": "...", "answer": "..."} '
              "Ð½Ðµ Ð´Ð¾Ð±Ð°Ð²Ð»ÑÐ¹ Ð½Ð¸Ñ‡ÐµÐ³Ð¾ Ð»Ð¸ÑˆÐ½ÐµÐ³Ð¾.")
    response = await client.chat.completions.create(
        model="gpt-3.5-turbo",
        temperature=0.7,
        max_tokens=200,
        messages=[{"role": "system", "content": system}]
    )
    import json
    data = json.loads(response.choices[0].message.content)
    return data["question"], data["answer"]

async def check_quiz_answer(user_answer: str, correct_answer: str) -> bool:
    return correct_answer.lower() in user_answer.lower()
