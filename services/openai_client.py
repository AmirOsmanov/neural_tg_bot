# services/openai_client.py

import logging
from openai import AsyncOpenAI
from config import CHATGPT_TOKEN

logger = logging.getLogger(__name__)
client = AsyncOpenAI(api_key=CHATGPT_TOKEN)


async def get_random_fact() -> str:
    """
    –ü–æ–ª—É—á–∏—Ç—å —Å–ª—É—á–∞–π–Ω—ã–π —Ñ–∞–∫—Ç –æ—Ç ChatGPT.
    """
    try:
        response = await client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {
                    "role": "system",
                    "content": (
                        "–¢—ã –ø–æ–º–æ—â–Ω–∏–∫, –∫–æ—Ç–æ—Ä—ã–π —Ä–∞—Å—Å–∫–∞–∑—ã–≤–∞–µ—Ç "
                        "–∏–Ω—Ç–µ—Ä–µ—Å–Ω—ã–µ –∏ –ø–æ–∑–Ω–∞–≤–∞—Ç–µ–ª—å–Ω—ã–µ —Ñ–∞–∫—Ç—ã. "
                        "–û—Ç–≤–µ—á–∞–π –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ."
                    )
                },
                {
                    "role": "user",
                    "content": (
                        "–†–∞—Å—Å–∫–∞–∂–∏ –∏–Ω—Ç–µ—Ä–µ—Å–Ω—ã–π —Å–ª—É—á–∞–π–Ω—ã–π —Ñ–∞–∫—Ç –∏–∑ "
                        "–ª—é–±–æ–π –æ–±–ª–∞—Å—Ç–∏ –∑–Ω–∞–Ω–∏–π. –§–∞–∫—Ç –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å "
                        "–ø–æ–∑–Ω–∞–≤–∞—Ç–µ–ª—å–Ω—ã–º, —É–¥–∏–≤–∏—Ç–µ–ª—å–Ω—ã–º –∏ –Ω–µ —Å–ª–∏—à–∫–æ–º "
                        "–¥–ª–∏–Ω–Ω—ã–º (–º–∞–∫—Å–∏–º—É–º 3‚Äì4 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è)."
                    )
                }
            ],
            max_tokens=200,
            temperature=0.8
        )
        fact = response.choices[0].message.content.strip()
        logger.info("–§–∞–∫—Ç —É—Å–ø–µ—à–Ω–æ –ø–æ–ª—É—á–µ–Ω –æ—Ç OpenAI")
        return fact

    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ —Ñ–∞–∫—Ç–∞ –æ—Ç OpenAI: {e}")
        return "ü§î –ö —Å–æ–∂–∞–ª–µ–Ω–∏—é, –Ω–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Ñ–∞–∫—Ç –≤ –¥–∞–Ω–Ω—ã–π –º–æ–º–µ–Ω—Ç."


async def ask_chatgpt(messages) -> str:
    """
    –û—Ç–ø—Ä–∞–≤–∫–∞ –ø—Ä–æ–∏–∑–≤–æ–ª—å–Ω–æ–≥–æ —Å–ø–∏—Å–∫–∞ —Å–æ–æ–±—â–µ–Ω–∏–π (system + user) –≤ ChatGPT –∏ –ø–æ–ª—É—á–µ–Ω–∏–µ –æ—Ç–≤–µ—Ç–∞.
    messages: List[{"role":..., "content":...}]
    """
    try:
        response = await client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=messages,
            max_tokens=400,
            temperature=0.7
        )
        reply = response.choices[0].message.content.strip()
        logger.info("–û—Ç–≤–µ—Ç —É—Å–ø–µ—à–Ω–æ –ø–æ–ª—É—á–µ–Ω –æ—Ç OpenAI")
        return reply

    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—â–µ–Ω–∏–∏ —Å ChatGPT: {e}")
        return "üòî –ö —Å–æ–∂–∞–ª–µ–Ω–∏—é, –Ω–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –æ—Ç–≤–µ—Ç –æ—Ç ChatGPT."

async def get_quiz_question(theme: str) -> tuple[str, str]:
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∫–æ—Ä—Ç–µ–∂ (question, correct_answer) –ø–æ –∑–∞–¥–∞–Ω–Ω–æ–π —Ç–µ–º–µ.
    """
    system = ("–¢—ã –ø–æ–º–æ—â–Ω–∏–∫-–≤–∏–∫—Ç–æ—Ä–∏–Ω–∞. –°—Ñ–æ—Ä–º—É–ª–∏—Ä—É–π –û–î–ò–ù –≤–æ–ø—Ä–æ—Å –ø–æ —Ç–µ–º–µ ¬´"
              f"{theme}¬ª –∏ –¥–∞–π –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç –≤ JSON:"
              r' {"question": "...", "answer": "..."} '
              "–Ω–µ –¥–æ–±–∞–≤–ª—è–π –Ω–∏—á–µ–≥–æ –ª–∏—à–Ω–µ–≥–æ.")
    response = await client.chat.completions.create(
        model="gpt-3.5-turbo",
        temperature=0.7,
        max_tokens=200,
        messages=[{"role": "system", "content": system}]
    )
    import json
    data = json.loads(response.choices[0].message.content)
    return data["question"], data["answer"]

async def check_quiz_answer(user_answer: str, correct_answer: str) -> bool:
    """
    –û—á–µ–Ω—å –ø—Ä–æ—Å—Ç–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞: –∏—Å–∫–∞—Ç—å correct_answer –≤ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–æ–º –≤–≤–æ–¥–µ
    (–Ω–µ–∫–µ–π—Å-—Å–µ–Ω—Å–∏—Ç–∏–≤). –ü—Ä–∏ –∂–µ–ª–∞–Ω–∏–∏ –º–æ–∂–Ω–æ —Å–¥–µ–ª–∞—Ç—å –∑–∞–ø—Ä–æ—Å –∫ GPT –¥–ª—è –≥–∏–±–∫–æ–π
    –ø—Ä–æ–≤–µ—Ä–∫–∏, –Ω–æ —ç—Ç–æ —É–≤–µ–ª–∏—á–∏—Ç –∑–∞–¥–µ—Ä–∂–∫—É –∏ —Ä–∞—Å—Ö–æ–¥ —Ç–æ–∫–µ–Ω–æ–≤.
    """
    return correct_answer.lower() in user_answer.lower()
